<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Data Science Notes</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async
                src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
        </script>
    </head>

    <body>
        <header>
            <h1>Data Science Notes</h1>
            <nav>
                <ul>
                    <li><a href="#Introduction">Introduction</a></li>
                    <li><a href="#Overview">Overview</a></li>
                    <li><a href="#DataPreparation">Data Preparation</a></li>
                    <li><a href="#PreformanceEvaluation">Preformance Evaluation</a></li>
                    <li><a href="#LearningMethods">Learning Methods</a>
                        <ul>
                            <li><a href="#kNN">k-Nearest Neighbors</a></li>
                            <li><a href="#NaiveBayes">Naive Bayes</a></li>
                            <li><a href="#LinearRegression">Linear Regression</a></li>
                            <li><a href="#LogisticRegression">Logistic Regression</a></li>
                            <li><a href="#SVM">Support Vector Machines</a></li>
                            <li><a href="#DecisionTrees">Decision Trees</a></li>
                            <li><a href="#NeuralNetworks">Neural Networks</a></li>
                        </ul>
                    </li>
                    <li><a href="#EnsembleMethods">Ensemble Methods</a></li>
                    <li><a href="#AdditionalExamples">Additional Examples</a></li>
                    <li><a href="#References">References</a></li>
                </ul>
            </nav>
        </header>
        <main>
            <article>
                <section>
                    <h2 id="Introduction">Introduction</h2>
                    <p>
                        Data science is a broad field incorporating aspects of mathematics, statistics, and computation to understand and make use of data.
                        The term "data science" is relatively new and doesn't have a precise definition, but there is significant overlap with "artificial intelligence" and "machine learning".
                        There are two main types of data: numerical data and categorical data.
                        Often different techniques are required to work with each type, although it is usually possible to convert back and forth between the two types.
                    </p>
                    <p>
                        In practice, there are two types of tasks to accomplish: supervised learning and unsupervised learning.
                        Supervised learning seeks to learn a function which maps input data to output data.
                        Unsupervised learning seeks to discover patterns in input data.
                        For now these notes will only cover supervised learning.
                        The techniques used for supervised learning problems depend on whether the output data is numerical or categorical.
                        The task is called regression or classification in the case of numerical or categorical data, respectively.
                    </p>
                    <p>
                        The methods used to accomplish a learning task can be classified according to: their ability to update when given additional data and their level of abstractness.
                        In batch learning, the learning process must start from sratch to incorporate new data.
                        In online learning, the learning process will build on what has been learned previously.
                        Instance-based learning involves no abstraction and consists of rote memorization of data.
                        Model-based learning hypothesizes an abstract model which is fit to the data.
                    </p>
                    <p>
                        These differences can strongly effect the practical use of a learning process.
                        Common practical considerations include: training time, prediction time, required memory.
                        <table>
                            <tr>
                                <td></td>
                                <th>Batch Learning</th>
                                <th>Online Learning</th>
                            </tr>
                            <tr>
                                <th>Instance-based</th>
                                <td colspan="2">
                                    <ul>
                                        <li>0 training time</li>
                                        <li>prediction time scales with data size</li>
                                        <li>required memory scales with data size</li>
                                    </ul>
                                </td>
                            </tr>
                            <tr>
                                <th>Model-based</th>
                                <td>
                                    <ul>
                                        <li>can have long training time</li>
                                        <li>prediction time depends on model complexity</li>
                                        <li>required memory scales with data size</li>
                                    </ul>
                                </td>
                                <td>
                                    <ul>
                                        <li>training time can be small with frequent updates</li>
                                        <li>prediction time depends on model complexity</li>
                                        <li>required memory scales with new data size</li>
                                    </ul>
                                </td>
                            </tr>
                        </table>
                    </p>
                </section>
                <section>
                    <article>
                        <header>
                            <h2 id="Overview">Overview</h2>
                            <p>
                                We will work through a simple data science example to give an overview of the process and ideas.
                                A well-known source of data sets is the <a href="https://archive.ics.uci.edu/ml/index.php">UCI Machine Learning Repository</a>.
                                Here we will find the Iris data set, one of the most popular for beginners.
                                Computations and visualizations will be carried out in <a href="https://jupyter.org/">Jupyter Notebook</a> with <a href="https://www.python.org/">Python</a> using standard packages including <a href="https://numpy.org/">NumPy</a>, <a href="https://pandas.pydata.org/">Pandas</a>, <a href="https://matplotlib.org/">Matplotlib</a>, <a href="https://seaborn.pydata.org/">Seaborn</a>, and <a href="https://scikit-learn.org/stable/">SciKit learn</a>.
                            </p>
                            <nav>
                                <ol>
                                    <li><a href="#GetData">Get the Data</a></li>
                                    <li><a href="#SplitData">Split Data into Training and Testing Sets</a></li>
                                    <li><a href="#ExploreData">Explore the Data</a></li>
                                    <li><a href="#HypothesizeModels">Hypothesize Models</a></li>
                                    <li><a href="#Preprocessing">Clean/Preprocess the Data</a></li>
                                        <ul>
                                            <li>Deal with missing data</li>
                                            <li>Standardize format</li>
                                            <li>Normalize or other transformations</li>
                                        </ul>
                                    <li><a href="#OptimizeHyperparameters">Optimize Hyperparameters</a></li>
                                    <li><a href="#ModelSelection">Select Model or Ensemble</a></li>
                                    <li><a href="#EvaluateModel">Final Evaluation</a></li>
                                    <li><a href="#UseModel">Put in Use</a></li>
                                    <li><a href="#UpdateModel">Update with New Data</a></li>
                                </ol>
                            </nav>
                        </header>
                        <section>
                            <h3 id="#GetData">Get the Data</h3>
                            <p>
                                Let us fix some notation and structure for the data which is collected or downloaded.
                                Our data will be in table/matrix form.
                                Each row will correspond to an example taken from the population, and each column will correspond to a property of the example.
                                Often the final column will contain the output data and be separated from the rest of the input data.
                                We will denote the "matrix" of input data by \( X \) and the "vector" of output data by \( \mathbf{y} \).
                            </p>
                            <p>
                                The downloaded Iris data comes in the form of a csv file.
                                Each line of the file is a row of the matrix and commas separate the entries by column along each row.
                                The first two columns contain the sepal length and width respectively (in cm).
                                The next two columns contain the petal length and width respectively (in cm).
                                The final column contains the class of Iris: Setosa, Versicolour, or Virginica.
                                Note that the first four input properties are numerical while the output is categorical.
                            </p>
                            <p>
                                In jupyter, load the data with using
                                <pre>
                                    <code>
                                        data = pd.read_csv('iris.data', header=None, names=['SL', 'SW', 'PL', 'PW', 'C'])
                                    </code>
                                </pre>
                                Separate the input data from the output data using
                                <pre>
                                    <code>
                                        X = data.drop(['C'], axis=1)
                                        y = data[['C']].copy()
                                    </code>
                                </pre>
                                <aside>
                                    A common warning when working with Pandas DataFrames is "Setting with Copy Warning".
                                    The <code>.drop()</code> method will return a copy, and no warning is given when modifying.
                                    The expression <code>data[['C']]</code> also seems to return a copy, but to prevent the warning explicitly use the <code>.copy()</code> method.
                                </aside>
                            </p>
                        </section>
                        <section>
                            <h3 id="#SplitData">Split Data into Training and Testing Sets</h3>
                            <p>
                                In order to evaluate how well the machine learned the task, we must set aside some data to be used for testing.
                                It is important to not look at or use the test data so that the model is not overfit to these specific tests.
                                Such overfitting would leave us with misplaced confidence in our model when applying it to new data.
                            </p>
                            <p>
                                There is some freedom in how much of the data should be set aside.
                                A good rule of thumb is to use 20% for testing and 80% for training.
                                The simplest way to split is with uniform random selection.
                                However, sometimes it is desirable for the distribution of the test data to match the distribution of all the data.
                                A stratified split can be used to preserve a distribution.
                            </p>
                            <p>
                                In jupyter, we may split the data by selecting 20% uniformly at random using
                                <pre>
                                    <code>
                                        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
                                    </code>
                                </pre>
                                Alternatively, if we want the input and output data in the same DataFrame
                                <pre>
                                    <code>
                                        data_train, data_test = train_test_split(data, test_size=0.2, random_state=42)
                                    </code>
                                </pre>
                                <aside>
                                    As we will see some library functions expect all the data to be in the same DataFrame.
                                </aside>
                            </p>
                        </section>
                        <section>
                            <h3 id="#ExploreData">Explore the Data</h3>
                            <p>
                                Now that we have data from which the machine is ready to learn, we should explore the data.
                                The purpose of the exploration is to hypothesize which models and techniques will be the best to use.
                                Additionally, our goal in this phase is to identify problems with the data such as missing values, typographical errors, inconsistant formatting, outliers, and skewed distributions.
                            </p>
                            <p>
                                There are a handful of simple commands which will provide basic insights into the data.
                                The <code>.shape</code> property of a pandas DataFrame will display the number of rows and columns.
                                The <code>.head()</code> method of a DataFrame will display the first 5 rows of data.
                                The <code>.info()</code> method of a DataFrame is very useful, it will display the data type of each column and give the number of non-missing values in each column.
                                The <code>.describe()</code> method of a DataFrame will give a statistical summary (mean, standard deviation, min, max, and quartiles) of each numerical data column.
                                A seaborn function <code>sns.pairplot()</code> will create scatter plots for each pair of numerical columns as well as histograms for each numerical column.
                                <pre>
                                    <code>
                                        print('DataFrame Shape: ', data_train.shape)
                                        print('\nFirst 5 rows of DataFrame:\n', data_train.head())
                                        print('\nColumn Data Types and Number of Non-Missing Values:')
                                        data_train.info()
                                        print('\nStatistical Summary of Numeric Columns:\n', data_train.describe())
                                        sns.pairplot(data_train);
                                    </code>
                                </pre>
                                The output from <code>.shape</code> tells us there are 120 rows and 4 columns.
                                The output from the <code>.info()</code> method indicates that all 4 columns are numerical and that none of the entries are missing values.
                                The pairplot produces looks like
                                <figure>
                                    <img src="images/basic_pairplot_output.png" alt="Pairplot of Numerical Columns">
                                    <figcaption>
                                        Rows and columns of the pairplot are the numerical columns in the DataFrame. Along the diagonal are the histograms for the numerical columns and off the diagonal are scatter plots for each pair of numerical columns.
                                    </figcaption>
                                </figure>
                            </p>
                            <p>
                                When there is no numerical data within a DataFrame <code>.describe()</code> behaves slightly differently.
                                Furthermore, scatter plots should be replaced with frequency tables, and histograms replaced with countplots.
                                The code below gives simple insights to the categorical target column of iris-species
                                <pre>
                                    <code>
                                        print('DataFrame Shape: ', y_train.shape)
                                        print('\nFirst 5 rows of DataFrame:\n',y_train.head())
                                        print('\nColumn Data Types and Number of Non-Missing Values:')
                                        y_train.info()
                                        print('\nStatistical Summary of a Categorical Column:\n', y_train.describe())
                                        y_test.groupby(['C']).size()
                                        sns.countplot(y_train['C']);
                                    </code>
                                </pre>
                                The <code>.countplot()</code> output looks like
                                <figure>
                                    <img src="images/countplot_output.png" alt="Countplot of Categorical Variable">
                                    <figcaption>
                                        Plot showing the number of iris of each species.
                                    </figcaption>
                                </figure>
                            </p>
                            <p>
                                In some of the scatter plots we can see clusters.
                                In order to gain a deeper understanding of these patterns we should incorporate the species of each data point.
                                Either of the following commands will add color to the pairplot, so that the data points for the different species (Setosa, Versicolor, and Virginica) are colored differently.
                                <pre>
                                    <code>
                                        sns.pairplot(data_train, hue='C');
                                        sns.pairplot(pd.concat([X_train, y_train], axis=1), hue='C');
                                    </code>
                                </pre>
                                The output will look like
                                <figure>
                                    <img src="images/colored_pairplot_output.png" alt="Pairplot of Numerical Columns With Points Colored by Species">
                                    <figcaption>
                                        Rows and columns of the pairplot are the numerical columns in the DataFrame. Along the diagonal are the histograms for the numerical columns and off the diagonal are scatter plots for each pair of numerical columns. Each point is colored according to the species of that example.
                                    </figcaption>
                                </figure>
                                These scatter plots make it clear that we should be able to identify an iris as iris-setosa by measuring its petals and sepals.
                            </p>
                        </section>
                        <section>
                            <h3 id="#HypothesizeModels">Hypothesize Models</h3>
                            <p></p>
                        </section>
                    </article>
                </section>
            </article>
        </main>
        <footer>
                <aside>
                    <p>
                        Disclaimer: These notes may contain errors, omissions, and inconsistancies.
                        Communicating simply the general ideas is preferred over completeness and technical correctness.
                        This document may contain out-of-date information and should be regarded as a work in progress.
                    </p>
                </aside>
            <p>&copy; 2019 Gerrit Smith</p>
        </footer>
    </body>
</html>